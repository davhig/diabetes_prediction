{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model for Diabetes Prediction\n",
    "\n",
    "Objective: Build a predictive model to predict the likelihood of a patient having diabetes based on certain features.\n",
    "\n",
    "Dataset: The dataset \"diabetes\" contains information about the medical history of patients, including features like Glucose level, Blood Pressure, BMI, etc., and a target variable indicating whether the patient has diabetes (1) or not (0).\n",
    "\n",
    "GitHub Repository: https://github.com/davhig/diabetes_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0            6      148             72             35        0  33.6   \n",
      "1            1       85             66             29        0  26.6   \n",
      "2            8      183             64              0        0  23.3   \n",
      "3            1       89             66             23       94  28.1   \n",
      "4            0      137             40             35      168  43.1   \n",
      "\n",
      "   DiabetesPedigreeFunction  Age  Outcome  \n",
      "0                     0.627   50        1  \n",
      "1                     0.351   31        0  \n",
      "2                     0.672   32        1  \n",
      "3                     0.167   21        0  \n",
      "4                     2.288   33        1  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Pregnancies               768 non-null    int64  \n",
      " 1   Glucose                   768 non-null    int64  \n",
      " 2   BloodPressure             768 non-null    int64  \n",
      " 3   SkinThickness             768 non-null    int64  \n",
      " 4   Insulin                   768 non-null    int64  \n",
      " 5   BMI                       768 non-null    float64\n",
      " 6   DiabetesPedigreeFunction  768 non-null    float64\n",
      " 7   Age                       768 non-null    int64  \n",
      " 8   Outcome                   768 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n",
      "None\n",
      "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
      "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
      "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
      "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
      "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
      "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
      "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
      "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
      "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
      "\n",
      "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
      "count  768.000000                768.000000  768.000000  768.000000  \n",
      "mean    31.992578                  0.471876   33.240885    0.348958  \n",
      "std      7.884160                  0.331329   11.760232    0.476951  \n",
      "min      0.000000                  0.078000   21.000000    0.000000  \n",
      "25%     27.300000                  0.243750   24.000000    0.000000  \n",
      "50%     32.000000                  0.372500   29.000000    0.000000  \n",
      "75%     36.600000                  0.626250   41.000000    1.000000  \n",
      "max     67.100000                  2.420000   81.000000    1.000000  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"datasets_228_482_diabetes.csv\")\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(df.head())\n",
    "\n",
    "# Check the structure and summary statistics of the dataset\n",
    "print(df.info())\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " From the statistics, we can observe that there are some features with minimum values of 0, such as Glucose, BloodPressure, SkinThickness, Insulin, and BMI. These zero values are likely to represent missing or invalid data since it's not possible for these physiological measurements to be zero in most cases.\n",
    "\n",
    " To handle this situation, we are going to replace zero values in the features Glucose, BloodPressure, SkinThickness, Insulin, and BMI with NaN to clearly identify and isolate those values as missing data. Then, we  will use the median to replace those NaN values, as the median is more robust to outliers compared to the mean. And physiological measurements can sometimes have outliers. Additionally, it preserves the overall distribution of the data, ensuring that the replaced values are representative of typical values within the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregnancies                 0\n",
      "Glucose                     0\n",
      "BloodPressure               0\n",
      "SkinThickness               0\n",
      "Insulin                     0\n",
      "BMI                         0\n",
      "DiabetesPedigreeFunction    0\n",
      "Age                         0\n",
      "Outcome                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Replace zero values with NaN\n",
    "df[['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']] = df[['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']].replace(0, np.nan)\n",
    "\n",
    "# Impute NaN values with median\n",
    "df.fillna(df.median(), inplace=True)\n",
    "\n",
    "# Check if there are any missing values remaining\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into features and target variable\n",
    "X = df.drop('Outcome', axis=1)\n",
    "y = df['Outcome']\n",
    "\n",
    "# Split the dataset into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features by removing the mean and scaling to unit variance\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a Logistic Regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the testing set\n",
    "y_pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7532467532467533\n",
      "Precision: 0.6666666666666666\n",
      "Recall: 0.6181818181818182\n",
      "F1 Score: 0.6415094339622642\n",
      "ROC AUC Score: 0.7232323232323232\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"ROC AUC Score:\", roc_auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic regression model achieved an accuracy of approximately 75.32%. This indicates that the model correctly predicts whether a patient has diabetes or not around 75% of the time. Additionally, the precision of the model is approximately 66.67%, suggesting that when the model predicts a patient has diabetes, it is correct around 66.67% of the time. However, the recall of the model is approximately 61.82%, indicating that the model correctly identifies around 61.82% of patients who actually have diabetes.\n",
    "\n",
    "Furthermore, the F1 score, which is a harmonic mean of precision and recall, is approximately 64.15%. Lastly, the ROC AUC score, which measures the model's ability to discriminate between positive and negative instances, is approximately 72.32%. A higher ROC AUC score indicates better discrimination.\n",
    "\n",
    "In conclusion, the logistic regression model performs reasonably well in most areas, but there's still some room for improvement, especially in correctly identifying patients with diabetes. Considering the real-life impact of inaccurate predictions in healthcare, it's crucial to enhance the model's performance. False predictions could have serious consequences for patients, so it's important to minimize them as much as possible. This means we need to focus on refining the model to make it better at predicting diabetes.\n",
    "\n",
    "To improve the performance of the logistic regression model, we can implement feature engineerig by exploring the existing features and creating new features that may provide more predictive power, or feature selection by identifying and selecting the most relevant features that have the greatest impact on the target variable. This could be done with techniques such as L1 regularization (Lasso), recursive feature elimination (RFE), etc. Another option is to implement hyperparameter tuning with techniques such as grid search or randomized search.\n",
    "\n",
    "To define the next steps to follow, we will identify the logistic regression coefficients to quantify the impact of the independent variables on the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Feature  Coefficient\n",
      "1                   Glucose     1.102551\n",
      "5                       BMI     0.688767\n",
      "7                       Age     0.392364\n",
      "0               Pregnancies     0.222844\n",
      "6  DiabetesPedigreeFunction     0.203586\n",
      "3             SkinThickness     0.068664\n",
      "4                   Insulin    -0.138304\n",
      "2             BloodPressure    -0.151521\n"
     ]
    }
   ],
   "source": [
    "# Access the coefficients\n",
    "coefficients = model.coef_[0]\n",
    "\n",
    "# Create a DataFrame to display feature names and coefficients\n",
    "coef_df = pd.DataFrame({'Feature': X.columns, 'Coefficient': coefficients})\n",
    "coef_df.sort_values(by='Coefficient', ascending=False, inplace=True)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(coef_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic regression analysis reveals that Glucose, BMI, Age, and the number of Pregnancies are the most influential factors in predicting diabetes. Higher Glucose and BMI levels, along with advancing age and a higher number of pregnancies, increase the likelihood of diabetes. Family history of diabetes (DiabetesPedigreeFunction) also plays a significant role. While SkinThickness, as well as Insulin, shows a weak impact on the model's predictive power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Important Features: ['Glucose', 'BMI', 'Age', 'Pregnancies', 'DiabetesPedigreeFunction']\n",
      "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0            6    148.0           72.0           35.0    125.0  33.6   \n",
      "1            1     85.0           66.0           29.0    125.0  26.6   \n",
      "2            8    183.0           64.0           29.0    125.0  23.3   \n",
      "3            1     89.0           66.0           23.0     94.0  28.1   \n",
      "4            0    137.0           40.0           35.0    168.0  43.1   \n",
      "\n",
      "   DiabetesPedigreeFunction  Age  Outcome  Glucose_BMI  ...  Age_Pregnancies  \\\n",
      "0                     0.627   50        1       4972.8  ...              300   \n",
      "1                     0.351   31        0       2261.0  ...               31   \n",
      "2                     0.672   32        1       4263.9  ...              256   \n",
      "3                     0.167   21        0       2500.9  ...               21   \n",
      "4                     2.288   33        1       5904.7  ...                0   \n",
      "\n",
      "   Age_DiabetesPedigreeFunction  Pregnancies_Glucose  Pregnancies_BMI  \\\n",
      "0                        31.350                888.0            201.6   \n",
      "1                        10.881                 85.0             26.6   \n",
      "2                        21.504               1464.0            186.4   \n",
      "3                         3.507                 89.0             28.1   \n",
      "4                        75.504                  0.0              0.0   \n",
      "\n",
      "   Pregnancies_Age  Pregnancies_DiabetesPedigreeFunction  \\\n",
      "0              300                                 3.762   \n",
      "1               31                                 0.351   \n",
      "2              256                                 5.376   \n",
      "3               21                                 0.167   \n",
      "4                0                                 0.000   \n",
      "\n",
      "   DiabetesPedigreeFunction_Glucose  DiabetesPedigreeFunction_BMI  \\\n",
      "0                            92.796                       21.0672   \n",
      "1                            29.835                        9.3366   \n",
      "2                           122.976                       15.6576   \n",
      "3                            14.863                        4.6927   \n",
      "4                           313.456                       98.6128   \n",
      "\n",
      "   DiabetesPedigreeFunction_Age  DiabetesPedigreeFunction_Pregnancies  \n",
      "0                        31.350                                 3.762  \n",
      "1                        10.881                                 0.351  \n",
      "2                        21.504                                 5.376  \n",
      "3                         3.507                                 0.167  \n",
      "4                        75.504                                 0.000  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "# Identify important features based on coefficients\n",
    "important_features = coef_df[coef_df['Coefficient'].abs() > 0.2]['Feature'].tolist()\n",
    "print(\"Important Features:\", important_features)\n",
    "\n",
    "# Create new features based on important features and their interactions\n",
    "for feature in important_features:\n",
    "    # Example: Creating polynomial features\n",
    "    #df[feature + '_squared'] = df[feature] ** 2\n",
    "    # Example: Creating interaction terms with other important features\n",
    "    for other_feature in important_features:\n",
    "        if other_feature != feature:\n",
    "            df[feature + '_' + other_feature] = df[feature] * df[other_feature]\n",
    "\n",
    "# Check if new features have been successfully added\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into features and target variable\n",
    "X = df.drop('Outcome', axis=1)\n",
    "y = df['Outcome']\n",
    "\n",
    "# Split the dataset into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features by removing the mean and scaling to unit variance\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a Logistic Regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the testing set\n",
    "y_pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7532467532467533\n",
      "Precision: 0.660377358490566\n",
      "Recall: 0.6363636363636364\n",
      "F1 Score: 0.6481481481481481\n",
      "ROC AUC Score: 0.7272727272727272\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"ROC AUC Score:\", roc_auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After implementing feature engineering, there was only marginal improvement in the performance metrics compared to the initial model. While precision and ROC AUC score slightly increased, the overall accuracy, recall, and F1 score remained similar. This suggests that the feature engineering techniques applied did not lead to significant enhancements in the model's ability to predict diabetes. Further exploration of alternative approaches may be necessary to achieve bigger improvements in performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'C': 0.1, 'penalty': 'l2'}\n",
      "Best Cross-validation Score: 0.7671331467413035\n",
      "Accuracy: 0.7597402597402597\n",
      "Precision: 0.6730769230769231\n",
      "Recall: 0.6363636363636364\n",
      "F1 Score: 0.6542056074766355\n",
      "ROC AUC Score: 0.7323232323232323\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Define the logistic regression model\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'penalty': ['l2'],  # Regularization penalty\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100]  # Inverse regularization strength\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(estimator=logreg, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Get the best cross-validation score\n",
    "best_score = grid_search.best_score_\n",
    "print(\"Best Cross-validation Score:\", best_score)\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"ROC AUC Score:\", roc_auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After implementing grid search to tune hyperparameters, there was a slight improvement in the performance metrics compared to the previous model. The accuracy increased from 75.32% to 75.97%, and precision improved from 66.04% to 67.31%. However, recall remained the same at 63.64%, and the F1 score increased from 64.81% to 65.42%. The ROC AUC score also saw a slight improvement, rising from 72.73% to 73.23%.\n",
    "\n",
    "Overall, while grid search helped optimize the logistic regression model's hyperparameters, the improvements in performance metrics were modest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the trained model to a pickle file\n",
    "with open('diabetes_lr_model.pkl', 'wb') as file:\n",
    "    pickle.dump(best_model, file)\n",
    "\n",
    "# Save the scaler to a pickle file\n",
    "with open('diabetes_scaler.pkl', 'wb') as file:\n",
    "    pickle.dump(scaler, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
